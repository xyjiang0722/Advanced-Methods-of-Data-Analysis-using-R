---
title: "R Notebook"
output:
  word_document: default
  html_notebook: default
---
Name: Xiaoyan Jiang

4. 
```{r}
library(faraway)
data(death)
```

(a).
```{r}
(ct=xtabs(y~penalty+defend,death))
prop.table(ct,1)
```
The marginal association shows that white people are more likely to be given a death penalty than black people.

```{r}
summary(ct)
fisher.test(matrix(c(149,17,141,19),ncol=2))
```
The observed differences in the frequency of application of the death penalty are not statistically significant by the Pearson's chi-square test and Fisher's test.

```{r}
(ctw=xtabs(y~penalty+defend,death,subset=(victim=='w')))
prop.table(ctw,1)
(ctb=xtabs(y~penalty+defend,death,subset=(victim=='b')))
prop.table(ctb,1)
```
The conditional association observed with in racial groups shows that black people are more likely to be given a death penalty than white people.

```{r}
summary(ctw)
summary(ctb)
```
The conditional associations are both not statistically significant.
This is an example of Simpsonâ€™s paradox, because the marginal association is different from the conditional associations.

(b).
```{r}
modi=glm(y~penalty+victim+defend,death,family=poisson)
c(deviance(modi),df.residual(modi),pchisq(deviance(modi),df.residual(modi),lower=F))
```
The independence model does not fit the data.

```{r}
modj=glm(y~penalty*defend+victim,death,family=poisson)
c(deviance(modj),df.residual(modj),pchisq(deviance(modj),df.residual(modj),lower=F))
```
The joint independence model does not fit the data.

```{r}
modc=glm(y~penalty*victim+defend*victim,death,family=poisson)
c(deviance(modc),df.residual(modc),pchisq(deviance(modc),df.residual(modc),lower=F))
```
The conditional independence model fits the data.

```{r}
modu=glm(y~(penalty+victim+defend)^2,death,family=poisson)
c(deviance(modu),df.residual(modu),pchisq(deviance(modu),df.residual(modu),lower=F))
anova(modc,modu,test='Chi')
```
The uniform association independence model fits the data. Including the penalty:defend interaction term does not improve the fit, so it may be dropped.

```{r}
modsat=glm(y~penalty*victim*defend,death,family=poisson)
drop1(modsat,test='Chi')
drop1(modu,test='Chi')
```
The three-way interaction term and the penalty:defend interaction term may be dropped. So the most appropriate dependence model is the conditional independence model.

(c).
```{r}
ybin=matrix(c(19,0,11,6,132,9,52,97),ncol=2)
modbin=glm(ybin~defend*victim,death[c(1,3,5,7),],family=binomial)
drop1(modbin,test='Chi')
```

```{r}
modbin1=glm(ybin~defend+victim,death[c(1,3,5,7),],family=binomial)
drop1(modbin1,test='Chi')
```

```{r}
modbin2=glm(ybin~victim,death[c(1,3,5,7),],family=binomial)
drop1(modbin2,test='Chi')
```
The binomial model that fits the data best is the one after dropping the defend:victim interaction term and defend. So the binomial model is penalty~victim.

```{r}
deviance(modbin2)
deviance(modc)

ctf0=xtabs(fitted(modc)~penalty+victim+defend,death)
apply(ctf0,3,function(x) (x[1,1]*x[2,2])/(x[1,2]*x[2,1]))
exp(coef(modbin2)[2])
```
The binomial model has identical deviances and the same ratio as in Poisson model in the previous question. So the binomial model and the Poisson model are identical.


5.
```{r}
data(leafblotch)
```

(a).
```{r}
plot(blotch~site, leafblotch)
plot(blotch~variety, leafblotch)
```
Blotch increases from site 1 to 9 and from variety 1 to 10. And the increase becomes more significant when the site number or the variety number gets larger.

(b).
```{r}
binmod=glm(blotch~site+variety, leafblotch, family=binomial(link = "logit"))
c(deviance(binmod),df.residual(binmod),pchisq(deviance(binmod),df.residual(binmod),lower=F))
```
The deviance is small in terms of degrees of freedom, and the chi-square test suggests that the binomial model fits the data.

(c).
```{r}
quasibinmod=glm(blotch~site+variety, leafblotch, family=quasibinomial(link='logit'))
summary(quasibinmod)
```
The value of the dispersion parameter is 0.08878094.
```{r}
deviance(binmod)/df.residual(binmod)
summary(quasibinmod)$dispersion
```
This dispersion estimate can be derived from the binomial GLM by dividing the deviance by its degree of freedom.

(d).
```{r}
plot(quasibinmod, 1)
```
The assumption of constant variance is violated, and there exists the issue of heteroskedasticity.

(e).
```{r}
y=leafblotch$blotch; mu=y
w=mu*(1-mu)
quasibinmod1=glm(blotch~site+variety, leafblotch, family=quasi(link='logit',variance="mu(1-mu)"), weights=w)
plot(quasibinmod1,1)
```
The variances in terms of residuals are smaller compared with the former model, but there still exists heteroskedascitity, implying that the model may not be a good fit.

(f).
```{r}
drop1(quasibinmod1, test = "F")
```
All predictors are statistically significant relative to the full model using an F-test. 

(g).
```{r}
intbinmod=glm(blotch~(site+variety)^2, leafblotch, family=binomial)
summary(intbinmod)
```
No combination between site and variety shows indication of an interaction.